{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/qmoKRL3SB1pUuLK6TzGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "873432b27df043d998c1be4fa3229757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b597d64d0cb84c0a9b94a82763a3116d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_811966968a404471ab37df6dc0bd5c83",
              "IPY_MODEL_2470aa5e8cc746b6a618b6ffa6177f90",
              "IPY_MODEL_a74147cc0bcb4caa961984e90253cf47"
            ]
          }
        },
        "b597d64d0cb84c0a9b94a82763a3116d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "811966968a404471ab37df6dc0bd5c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa1611d2df8c46f8a1928d9559749fff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epochs completed: 100%| ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_325de2c476524c84981f0881078660c6"
          }
        },
        "2470aa5e8cc746b6a618b6ffa6177f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_156c6d8c2c0343138356f350e303e5e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_002d787ba85a4b04a28d8113defcdc1a"
          }
        },
        "a74147cc0bcb4caa961984e90253cf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e40375b6a4d4a98915ebc0c88b961e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:03]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f55701cea264b0dab3a92e5a9b59c60"
          }
        },
        "fa1611d2df8c46f8a1928d9559749fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "325de2c476524c84981f0881078660c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "156c6d8c2c0343138356f350e303e5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "002d787ba85a4b04a28d8113defcdc1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e40375b6a4d4a98915ebc0c88b961e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f55701cea264b0dab3a92e5a9b59c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prith189/GLG_DL/blob/main/Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline suggested by BERTopic:\n",
        "\n",
        "- Generate embeddings using the Sentence Transformer model (Each block of text is converted to a 384 dimensional vector)\n",
        "\n",
        "- Reduce the dimensionality using UMAP for 384 dimensions to 5 dimensions\n",
        "\n",
        "- Cluster the 5 dimensional vectors using HDBSCAN\n",
        "\n",
        "- For each cluster, run TF-IDF to generate a representation of the topic\n",
        "\n",
        "\n",
        "Changes made to use the News dataset\n",
        "\n",
        "- For clustering, HDBSCAN classifies most of the vectors in the embedded space as noise\n",
        "\n",
        "- Kmeans clusters all data points into clusters, therefore KMeans was used\n",
        "\n",
        "- In the below notebook, UMAP was used for dimensionality reduction and Kmeans was used for clustering"
      ],
      "metadata": {
        "id": "JbOIkY2eGZwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RUN_SENTENCE_TRANSFORMER = False #Set this to True if we need to generate embeddings from scratch. Requires GPU else very slow.\n",
        "RUN_UMAP = False #Set this to True if we need to reduce the dimensionality of the embeddings using UMAP (Requires >100GB of RAM to run for all data points)\n",
        "RUN_KMEANS = True #Set this to True if we need to run KMeans on the reduce dimension vectors\n",
        "EXTRACT_TOPICS = True #Set this to True to extract a description of each of the topics\n",
        "TEST_NEW_TEXT = True #To test out new topics"
      ],
      "metadata": {
        "id": "T6s_D_VcDGyC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ndoYr_ndCNy",
        "outputId": "f924b62a-2ad3-45c7-bc15-82d89a14b45a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.62.3)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.5.6)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece] sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMngECgWd8Gu",
        "outputId": "0186c079-9e22-4270-bafb-23be411d1a50"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.5.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (5.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_drive = False"
      ],
      "metadata": {
        "id": "aVObnKdermt0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(use_drive):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_PATH = '/content/drive/My Drive/fourthbrain/'\n",
        "else:\n",
        "    BASE_PATH = '/content/'"
      ],
      "metadata": {
        "id": "1jaZ5aaVqCWP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pjRzTHFltMxb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EMBEDDINGS FILE\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-3gKYoipfdPkeQHnHa0M2vD7QEug5wNS' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-3gKYoipfdPkeQHnHa0M2vD7QEug5wNS\" -O all-the-news-embeddings-title.npy && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "q5Xh6qePlYj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb192567-76b3-4e23-9dad-fb5b072f2c7c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-11 15:12:09--  https://docs.google.com/uc?export=download&confirm=t&id=1-3gKYoipfdPkeQHnHa0M2vD7QEug5wNS\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.189.14, 2607:f8b0:4007:817::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0nv58re3np3dmph6a780kqp3rcun5ds9/1652281875000/11484953962162697849/*/1-3gKYoipfdPkeQHnHa0M2vD7QEug5wNS?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-05-11 15:12:10--  https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0nv58re3np3dmph6a780kqp3rcun5ds9/1652281875000/11484953962162697849/*/1-3gKYoipfdPkeQHnHa0M2vD7QEug5wNS?e=download\n",
            "Resolving doc-0c-5g-docs.googleusercontent.com (doc-0c-5g-docs.googleusercontent.com)... 142.250.72.225, 2607:f8b0:4007:816::2001\n",
            "Connecting to doc-0c-5g-docs.googleusercontent.com (doc-0c-5g-docs.googleusercontent.com)|142.250.72.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4130059904 (3.8G) [application/octet-stream]\n",
            "Saving to: ‘all-the-news-embeddings-title.npy’\n",
            "\n",
            "all-the-news-embedd 100%[===================>]   3.85G   260MB/s    in 15s     \n",
            "\n",
            "2022-05-11 15:12:25 (255 MB/s) - ‘all-the-news-embeddings-title.npy’ saved [4130059904/4130059904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#INDEX FILE for NEWS DATASET (so that the embeddings file matches the entries from the news.csv file)\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-5IsScXPtUY5jXVe_83RuQ0uI7eQqDMI' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-5IsScXPtUY5jXVe_83RuQ0uI7eQqDMI\" -O all-the-news-embeddings-title-index.npy && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "XiYN4sZSl3Ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec65ca9-de7e-4d53-9562-42f3e1a24cbe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-11 15:12:38--  https://docs.google.com/uc?export=download&confirm=&id=1-5IsScXPtUY5jXVe_83RuQ0uI7eQqDMI\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.189.14, 2607:f8b0:4007:817::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mf5mfvr3nhpnp7komq40e6pop9q87tsj/1652281950000/11484953962162697849/*/1-5IsScXPtUY5jXVe_83RuQ0uI7eQqDMI?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-05-11 15:12:38--  https://doc-10-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mf5mfvr3nhpnp7komq40e6pop9q87tsj/1652281950000/11484953962162697849/*/1-5IsScXPtUY5jXVe_83RuQ0uI7eQqDMI?e=download\n",
            "Resolving doc-10-5g-docs.googleusercontent.com (doc-10-5g-docs.googleusercontent.com)... 142.250.72.225, 2607:f8b0:4007:816::2001\n",
            "Connecting to doc-10-5g-docs.googleusercontent.com (doc-10-5g-docs.googleusercontent.com)|142.250.72.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21510856 (21M) [application/octet-stream]\n",
            "Saving to: ‘all-the-news-embeddings-title-index.npy’\n",
            "\n",
            "all-the-news-embedd 100%[===================>]  20.51M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-05-11 15:12:39 (164 MB/s) - ‘all-the-news-embeddings-title-index.npy’ saved [21510856/21510856]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Cr0YuS85hynqfi_4_Kr99h4HTTUpsZ-u' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Cr0YuS85hynqfi_4_Kr99h4HTTUpsZ-u\" -O all-the-news-2-1.csv && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "TUy-wUptqppS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028858f2-14f2-4dd6-aa73-6bde5bfb9b0f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-11 15:13:28--  https://docs.google.com/uc?export=download&confirm=&id=1Cr0YuS85hynqfi_4_Kr99h4HTTUpsZ-u\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.189.14, 2607:f8b0:4007:817::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘all-the-news-2-1.csv’\n",
            "\n",
            "all-the-news-2-1.cs     [ <=>                ]   1.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-11 15:13:28 (32.6 MB/s) - ‘all-the-news-2-1.csv’ saved [1993]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "class FeatureExtraction:\n",
        "    def __init__(self):\n",
        "        #Load the pretrained model\n",
        "        self.fe = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=0)\n",
        "\n",
        "    def run_fe_batch(self, list_of_input_text):\n",
        "        list_of_fe_vec = self.fe.encode(list_of_input_text, show_progress_bar=False)\n",
        "        return list_of_fe_vec\n",
        "\n",
        "\n",
        "class NewsDataset:\n",
        "    def __init__(self):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.preprocess()\n",
        "        self.ner = None\n",
        "    \n",
        "    def preprocess(self):\n",
        "        self.df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1','date','year','month','day','article','publication'], inplace=True)\n",
        "        print('Shape of dataframe before dropping nan:{}'.format(self.df.shape))\n",
        "        self.df = self.df.dropna(subset=['title'])\n",
        "        print('Shape of dataframe after dropping nan:{}'.format(self.df.shape))"
      ],
      "metadata": {
        "id": "HJew44yNfXPk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_file = os.path.join(BASE_PATH, 'embeddings-title.npy')\n",
        "idx_file = os.path.join(BASE_PATH, 'all-the-news-embeddings-title-index.npy')\n",
        "if(RUN_SENTENCE_TRANSFORMER):    \n",
        "    feature_extractor = FeatureExtraction()\n",
        "    news = NewsDataset()\n",
        "    df_text = news.df['title'].to_list()\n",
        "    features = feature_extractor.run_fe_batch(df_text)\n",
        "    df_idx = news.df.index\n",
        "    np.save(features_file, features)\n",
        "    np.save(idx_file, df_idx)\n",
        "else:\n",
        "    features = np.load(features_file)\n",
        "    df_idx = np.load(idx_file)"
      ],
      "metadata": {
        "id": "dctgR57meE-2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_red_embeddings_file = os.path.join(BASE_PATH, 'embeddings-title-umap.npy')\n",
        "umap_model_file = os.path.join(BASE_PATH, 'umap-model.sav')\n",
        "if(RUN_UMAP):\n",
        "    from umap import UMAP\n",
        "    umap_model = UMAP(n_neighbors=15,n_components=5,min_dist=0.0,metric='cosine',low_memory=True, verbose=True)\n",
        "    umap_model.fit(features)\n",
        "    dim_red_embeddings = umap_model.transform(features)\n",
        "    np.save(dim_red_embeddings_file, dim_red_embeddings)\n",
        "    #f = open(umap_model_file, 'wb')\n",
        "    #pickle.dump(umap_model, f)\n",
        "    #f.close()\n",
        "    joblib.dump(umap_model, umap_model_file, protocol=4)\n",
        "else:\n",
        "    dim_red_embeddings = np.load(dim_red_embeddings_file)\n",
        "    #f = open(umap_model_file, 'rb')\n",
        "    #umap_model_2 = pickle.load(f)\n",
        "    #f.close()\n",
        "    umap_model = joblib.load(umap_model_file)"
      ],
      "metadata": {
        "id": "N_ISZu83aXgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af858dd-4d79-41f3-94ed-84132c848b0a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 11 15:12:54 2022 Building and compiling search function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JvHjkjSXcXYH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "WtIyOjXSbeFA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "uIaKQMbCb9NT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploaded = drive.CreateFile({'title': umap_model_file})\n",
        "# uploaded.SetContentFile('/content/umap-model.sav')\n",
        "# uploaded.Upload()"
      ],
      "metadata": {
        "id": "lC2YBCj5cOIl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_model_file = os.path.join(BASE_PATH, 'kmeans_model.p')\n",
        "labels_file = os.path.join(BASE_PATH, 'umap-kmeans-labels.npy')\n",
        "import pickle as p\n",
        "if(RUN_KMEANS):\n",
        "    from sklearn.cluster import MiniBatchKMeans\n",
        "    kmn = MiniBatchKMeans(n_clusters=25, verbose=1)\n",
        "    labels = kmn.fit_predict(dim_red_embeddings)\n",
        "    print('Number of datapoints in each cluster---')\n",
        "    print(np.unique(labels, return_counts=True))\n",
        "    f = open(kmeans_model_file, 'wb')\n",
        "    pickle.dump(kmn, f)\n",
        "    f.close()\n",
        "    np.save(labels_file, labels)\n",
        "else:\n",
        "    f = open(kmeans_model_file, 'rb')\n",
        "    kmn = pickle.load(f)\n",
        "    f.close()\n",
        "    labels = np.load(labels_file)"
      ],
      "metadata": {
        "id": "7UzamtU4qIS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411e82ee-b65c-4815-cc70-6c242e85cc71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init 1/3 with method k-means++\n",
            "Inertia for init 1/3: 16049.197265625\n",
            "Init 2/3 with method k-means++\n",
            "Inertia for init 2/3: 16319.5341796875\n",
            "Init 3/3 with method k-means++\n",
            "Inertia for init 3/3: 15246.818359375\n",
            "[MiniBatchKMeans] Reassigning 4 cluster centers.\n",
            "Minibatch step 1/262582: mean batch inertia: 5.3456902503967285\n",
            "Minibatch step 2/262582: mean batch inertia: 4.77610445022583, ewa inertia: 4.77610445022583\n",
            "Minibatch step 3/262582: mean batch inertia: 5.150442600250244, ewa inertia: 4.7763895709325315\n",
            "Minibatch step 4/262582: mean batch inertia: 5.852754592895508, ewa inertia: 4.777209401761186\n",
            "Minibatch step 5/262582: mean batch inertia: 4.447000503540039, ewa inertia: 4.776957892812889\n",
            "Minibatch step 6/262582: mean batch inertia: 3.9681670665740967, ewa inertia: 4.776341864198289\n",
            "Minibatch step 7/262582: mean batch inertia: 5.829909324645996, ewa inertia: 4.777144330895476\n",
            "Minibatch step 8/262582: mean batch inertia: 5.9945969581604, ewa inertia: 4.778071623380731\n",
            "Minibatch step 9/262582: mean batch inertia: 3.7588071823120117, ewa inertia: 4.777295284133089\n",
            "Minibatch step 10/262582: mean batch inertia: 4.290983200073242, ewa inertia: 4.776924876668406\n",
            "Minibatch step 11/262582: mean batch inertia: 4.433002471923828, ewa inertia: 4.7766629226060555\n",
            "Minibatch step 12/262582: mean batch inertia: 5.043607234954834, ewa inertia: 4.776866245059249\n",
            "Converged (lack of improvement in inertia) at step 12/262582\n",
            "Number of datapoints in each cluster---\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24], dtype=int32), array([119793, 229485,  94393, 167411,  14667, 115694,  84714,  52763,\n",
            "       135487,  59824,  55177,  74530,  77384, 213664, 201013,  74562,\n",
            "        83262,  99410, 131373, 146749,  81921, 153301,  37202,  31208,\n",
            "       153854]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions were copied from the BERTopic module to extract topic descriptions from a set of clusters\n",
        "\n",
        "import re\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.utils import check_array\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "\n",
        "class ClassTFIDF(TfidfTransformer):\n",
        "    \"\"\"\n",
        "    A Class-based TF-IDF procedure using scikit-learns TfidfTransformer as a base.\n",
        "    ![](../img/ctfidf.png)\n",
        "    C-TF-IDF can best be explained as a TF-IDF formula adopted for multiple classes\n",
        "    by joining all documents per class. Thus, each class is converted to a single document\n",
        "    instead of set of documents. Then, the frequency of words **t** are extracted for\n",
        "    each class **i** and divided by the total number of words **w**.\n",
        "    Next, the total, unjoined, number of documents across all classes **m** is divided by the total\n",
        "    sum of word **i** across all classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(ClassTFIDF, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def fit(self, X, multiplier):\n",
        "        \"\"\"Learn the idf vector (global term weights).\n",
        "        Arguments:\n",
        "            X: A matrix of term/token counts.\n",
        "            multiplier: A multiplier for increasing/decreasing certain IDF scores\n",
        "        \"\"\"\n",
        "        X = check_array(X, accept_sparse=('csr', 'csc'))\n",
        "        if not sp.issparse(X):\n",
        "            X = sp.csr_matrix(X)\n",
        "        dtype = np.float64\n",
        "\n",
        "        if self.use_idf:\n",
        "            _, n_features = X.shape\n",
        "\n",
        "            # Calculate the frequency of words across all classes\n",
        "            df = np.squeeze(np.asarray(X.sum(axis=0)))\n",
        "\n",
        "            # Calculate the average number of samples as regularization\n",
        "            avg_nr_samples = int(X.sum(axis=1).mean())\n",
        "\n",
        "            # Divide the average number of samples by the word frequency\n",
        "            # +1 is added to force values to be positive\n",
        "            idf = np.log((avg_nr_samples / df)+1)\n",
        "\n",
        "            # Multiplier to increase/decrease certain idf scores\n",
        "            if multiplier is not None:\n",
        "                idf = idf * multiplier\n",
        "\n",
        "            self._idf_diag = sp.diags(idf, offsets=0,\n",
        "                                      shape=(n_features, n_features),\n",
        "                                      format='csr',\n",
        "                                      dtype=dtype)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform a count-based matrix to c-TF-IDF\n",
        "        Arguments:\n",
        "            X (sparse matrix): A matrix of term/token counts.\n",
        "        Returns:\n",
        "            X (sparse matrix): A c-TF-IDF matrix\n",
        "        \"\"\"\n",
        "        if self.use_idf:\n",
        "            X = normalize(X, axis=1, norm='l1', copy=False)\n",
        "            X = X * self._idf_diag\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "def c_tf_idf(documents_per_topic):\n",
        "    \"\"\" Calculate a class-based TF-IDF where m is the number of total documents.\n",
        "    Arguments:\n",
        "        documents_per_topic: The joined documents per topic such that each topic has a single\n",
        "                              string made out of multiple documents\n",
        "        m: The total number of documents (unjoined)\n",
        "        fit: Whether to fit a new vectorizer or use the fitted self.vectorizer_model\n",
        "    Returns:\n",
        "        tf_idf: The resulting matrix giving a value (importance score) for each word per topic\n",
        "        words: The names of the words to which values were given\n",
        "    \"\"\"\n",
        "    documents = preprocess_text(documents_per_topic['title'].values)\n",
        "\n",
        "    vectorizer_model = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
        "\n",
        "    vectorizer_model.fit(documents)\n",
        "\n",
        "    words = vectorizer_model.get_feature_names()\n",
        "    X = vectorizer_model.transform(documents)\n",
        "\n",
        "    transformer = ClassTFIDF().fit(X, multiplier=None)\n",
        "\n",
        "    c_tf_idf = transformer.transform(X)\n",
        "\n",
        "    topic_sim_matrix = cosine_similarity(c_tf_idf)\n",
        "\n",
        "    return c_tf_idf, words\n",
        "\n",
        "def preprocess_text(documents):\n",
        "    \"\"\" Basic preprocessing of text\n",
        "    Steps:\n",
        "        * Lower text\n",
        "        * Replace \\n and \\t with whitespace\n",
        "        * Only keep alpha-numerical characters\n",
        "    \"\"\"\n",
        "    cleaned_documents = [doc.lower() for doc in documents]\n",
        "    cleaned_documents = [doc.replace(\"\\n\", \" \") for doc in cleaned_documents]\n",
        "    cleaned_documents = [doc.replace(\"\\t\", \" \") for doc in cleaned_documents]\n",
        "    cleaned_documents = [re.sub(r'[^A-Za-z0-9 ]+', '', doc) for doc in cleaned_documents]\n",
        "    cleaned_documents = [doc if doc != \"\" else \"emptydoc\" for doc in cleaned_documents]\n",
        "    return cleaned_documents\n",
        "\n",
        "def top_n_idx_sparse(matrix, n):\n",
        "    \"\"\" Return indices of top n values in each row of a sparse matrix\n",
        "    Retrieved from:\n",
        "        https://stackoverflow.com/questions/49207275/finding-the-top-n-values-in-a-row-of-a-scipy-sparse-matrix\n",
        "    Arguments:\n",
        "        matrix: The sparse matrix from which to get the top n indices per row\n",
        "        n: The number of highest values to extract from each row\n",
        "    Returns:\n",
        "        indices: The top n indices per row\n",
        "    \"\"\"\n",
        "    indices = []\n",
        "    for le, ri in zip(matrix.indptr[:-1], matrix.indptr[1:]):\n",
        "        n_row_pick = min(n, ri - le)\n",
        "        values = matrix.indices[le + np.argpartition(matrix.data[le:ri], -n_row_pick)[-n_row_pick:]]\n",
        "        values = [values[index] if len(values) >= index + 1 else None for index in range(n)]\n",
        "        indices.append(values)\n",
        "    return np.array(indices)\n",
        "\n",
        "def top_n_values_sparse(matrix, indices):\n",
        "    \"\"\" Return the top n values for each row in a sparse matrix\n",
        "    Arguments:\n",
        "        matrix: The sparse matrix from which to get the top n indices per row\n",
        "        indices: The top n indices per row\n",
        "    Returns:\n",
        "        top_values: The top n scores per row\n",
        "    \"\"\"\n",
        "    top_values = []\n",
        "    for row, values in enumerate(indices):\n",
        "        scores = np.array([matrix[row, value] if value is not None else 0 for value in values])\n",
        "        top_values.append(scores)\n",
        "    return np.array(top_values)\n",
        "\n",
        "def extract_words_per_topic(words,c_tf_idf,labels):\n",
        "        \"\"\" Based on tf_idf scores per topic, extract the top n words per topic\n",
        "        If the top words per topic need to be extracted, then only the `words` parameter\n",
        "        needs to be passed. If the top words per topic in a specific timestamp, then it\n",
        "        is important to pass the timestamp-based c-TF-IDF matrix and its corresponding\n",
        "        labels.\n",
        "        Arguments:\n",
        "            words: List of all words (sorted according to tf_idf matrix position)\n",
        "            c_tf_idf: A c-TF-IDF matrix from which to calculate the top words\n",
        "            labels: A list of topic labels\n",
        "        Returns:\n",
        "            topics: The top words per topic\n",
        "        \"\"\"\n",
        "\n",
        "        # Get the top 30 indices and values per row in a sparse c-TF-IDF matrix\n",
        "        indices = top_n_idx_sparse(c_tf_idf, 30)\n",
        "        scores = top_n_values_sparse(c_tf_idf, indices)\n",
        "        sorted_indices = np.argsort(scores, 1)\n",
        "        indices = np.take_along_axis(indices, sorted_indices, axis=1)\n",
        "        scores = np.take_along_axis(scores, sorted_indices, axis=1)\n",
        "\n",
        "        # Get top 30 words per topic based on c-TF-IDF score\n",
        "        topics = {label: [(words[word_index], score)\n",
        "                          if word_index is not None and score > 0\n",
        "                          else (\"\", 0.00001)\n",
        "                          for word_index, score in zip(indices[index][::-1], scores[index][::-1])\n",
        "                          ]\n",
        "                  for index, label in enumerate(labels)}\n",
        "\n",
        "        # Extract word embeddings for the top 30 words per topic and compare it\n",
        "        # with the topic embedding to keep only the words most similar to the topic embedding\n",
        "        # if self.diversity is not None:\n",
        "        #     if self.embedding_model is not None:\n",
        "\n",
        "        #         for topic, topic_words in topics.items():\n",
        "        #             words = [word[0] for word in topic_words]\n",
        "        #             word_embeddings = self._extract_embeddings(words,\n",
        "        #                                                        method=\"word\",\n",
        "        #                                                        verbose=False)\n",
        "        #             topic_embedding = self._extract_embeddings(\" \".join(words),\n",
        "        #                                                        method=\"word\",\n",
        "        #                                                        verbose=False).reshape(1, -1)\n",
        "        #             topic_words = mmr(topic_embedding, word_embeddings, words,\n",
        "        #                               top_n=self.top_n_words, diversity=self.diversity)\n",
        "        #             topics[topic] = [(word, value) for word, value in topics[topic] if word in topic_words]\n",
        "        # topics = {label: values[:self.top_n_words] for label, values in topics.items()}\n",
        "\n",
        "        return topics"
      ],
      "metadata": {
        "id": "vqHqUHKlN1Ah"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics_file = os.path.join(BASE_PATH, 'umap-kmeans-topics.p')\n",
        "if(EXTRACT_TOPICS):\n",
        "    csv_file = os.path.join(BASE_PATH, 'news.csv')\n",
        "    df = pd.read_csv(csv_file, usecols=['title'])\n",
        "    df = df.iloc[df_idx]\n",
        "    df['Topic'] = labels\n",
        "    df = df[['title', 'Topic']]\n",
        "    n_topics = df['Topic'].unique().shape[0]\n",
        "    documents_per_topic = df.groupby(['Topic'], as_index=False).agg({'title': ' '.join})\n",
        "    sizes = df.groupby(['Topic']).count().sort_values(\"title\", ascending=False).reset_index()\n",
        "    topic_sizes = dict(zip(sizes['Topic'], sizes['title']))\n",
        "    labels = sorted(list(topic_sizes.keys()))\n",
        "    documents_per_topic = df.groupby(['Topic'], as_index=False).agg({'title': ' '.join})\n",
        "    c_tf_idf_m, words = c_tf_idf(documents_per_topic)\n",
        "    topics = extract_words_per_topic(words, c_tf_idf_m, labels)\n",
        "    f = open(topics_file, 'wb')\n",
        "    pickle.dump(topics, f)\n",
        "    f.close()\n",
        "else:\n",
        "    f = open(topics_file, 'rb')\n",
        "    topics = pickle.load(f)\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "AKCrfCVCv6_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4320149-f4af-4b8d-f660-5330a43b0028"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample_text():\n",
        "    st = []\n",
        "    st.append('Secret Service on the defensive over allegations agents were duped by men impersonating feds') #Government\n",
        "    st.append('Microsoft and other tech firms take aim at prolific cybercrime gang') #Technology\n",
        "    st.append('Phoenix Suns favorites to win NBA title, but they still feel disrespected. Are they overlooked?') #Sports\n",
        "    st.append(\"Natural gas spikes to highest level since 2008 as rare nor'easter looms\") #Business\n",
        "    st.append(\"Will rising prices sink Biden’s midterm hopes for Democrats?\") #Politics\n",
        "    st.append(\"Large and dangerous' tornadoes hit Texas and Oklahoma; South faces more severe weather\") #Climate\n",
        "    st.append(\"Here is a list of the best beaches in Hawaii and other tropical islands\") #Travel\n",
        "    return st"
      ],
      "metadata": {
        "id": "Qx3mQkU5lKWW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TEST_NEW_TEXT):\n",
        "    feature_extractor = FeatureExtraction()\n",
        "    new_text = get_sample_text()\n",
        "    test_embeddings = feature_extractor.run_fe_batch(new_text)\n",
        "    test_dim_red_embeddings = umap_model.transform(test_embeddings)\n",
        "    test_labels = list(kmn.predict(test_dim_red_embeddings))\n",
        "    for label, text in zip(test_labels, new_text):\n",
        "        print('Test text:', text)\n",
        "        print('Predicted topic:', '_'.join([i[0] for i in topics[label][:5]]))"
      ],
      "metadata": {
        "id": "nEMpm54WlELx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "873432b27df043d998c1be4fa3229757",
            "b597d64d0cb84c0a9b94a82763a3116d",
            "811966968a404471ab37df6dc0bd5c83",
            "2470aa5e8cc746b6a618b6ffa6177f90",
            "a74147cc0bcb4caa961984e90253cf47",
            "fa1611d2df8c46f8a1928d9559749fff",
            "325de2c476524c84981f0881078660c6",
            "156c6d8c2c0343138356f350e303e5e1",
            "002d787ba85a4b04a28d8113defcdc1a",
            "2e40375b6a4d4a98915ebc0c88b961e7",
            "6f55701cea264b0dab3a92e5a9b59c60"
          ]
        },
        "outputId": "2d7f9d64-a409-495b-c961-e2ba444f458c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "873432b27df043d998c1be4fa3229757",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Epochs completed:   0%|            0/100 [00:00]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test text: Secret Service on the defensive over allegations agents were duped by men impersonating feds\n",
            "Predicted topic: trump_thehill_trumps_clinton_donald\n",
            "Test text: Microsoft and other tech firms take aim at prolific cybercrime gang\n",
            "Predicted topic: twitter_thehill_opinion_new_college\n",
            "Test text: Phoenix Suns favorites to win NBA title, but they still feel disrespected. Are they overlooked?\n",
            "Predicted topic: preview_win_past_nfl_nba\n",
            "Test text: Natural gas spikes to highest level since 2008 as rare nor'easter looms\n",
            "Predicted topic: oil_update_saudi_fitch_huawei\n",
            "Test text: Will rising prices sink Biden’s midterm hopes for Democrats?\n",
            "Predicted topic: trump_thehill_trumps_clinton_donald\n",
            "Test text: Large and dangerous' tornadoes hit Texas and Oklahoma; South faces more severe weather\n",
            "Predicted topic: climate_boeing_thehill_climate change_air\n",
            "Test text: Here is a list of the best beaches in Hawaii and other tropical islands\n",
            "Predicted topic: dog_food_new_recipe_starbucks\n"
          ]
        }
      ]
    }
  ]
}